{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 各クラスタ内の重心ベクトルとoutlaierベクトルを取得して固有名詞ベクトルを制限する\n",
    "- 関係ベクトルを算出する\n",
    "- 関係ベクトルにをランダムで20%ずつ取得し、それぞれのクラスタを求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib \n",
    "from scipy import optimize\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # warningが出ないように設定\n",
    "pd.set_option(\"display.max_rows\", None) # pandasの表示上限をなくす\n",
    "pd.set_option(\"display.max_columns\", None) # pandasの表示上限をなくす\n",
    "import pickle\n",
    "from sklearn.cluster import DBSCAN\n",
    "import gspread\n",
    "import json\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import collections\n",
    "import gensim\n",
    "model = gensim.models.Word2Vec.load(\"../latest-ja-word2vec-gensim-model/word2vec.gensim.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../koyuu_noun_sample_list.binaryfile','rb')\n",
    "sample_vec_list = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 2 643 33999\n",
      "0.5 4 104 35525\n",
      "0.5 6 58 36312\n",
      "0.5 8 41 36845\n",
      "0.5 10 28 37302\n"
     ]
    }
   ],
   "source": [
    "# データ取得\n",
    "#eps minPts n_class\n",
    "\n",
    "file = \"../dbscan_koyuu_nomal_noun_fold/0.5_10_dic.binaryfile\"\n",
    "f = open(file,'rb')\n",
    "eps_minPts_dic = pickle.load(f)\n",
    "\n",
    "for eps, minPts_data in eps_minPts_dic.items():\n",
    "    for minPts, y_dbscan in minPts_data.items():\n",
    "            \n",
    "        n_class = np.max(y_dbscan) +1\n",
    "        n_outlier = len(np.where(y_dbscan == -1)[0])\n",
    "                \n",
    "        print(str(eps) +\" \"+ str(minPts) +\" \"+ str(n_class) +\" \" + str(n_outlier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dbscan = eps_minPts_dic[0.5][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0\n",
      "6369\n",
      "class 1\n",
      "36\n",
      "class 2\n",
      "5\n",
      "class 3\n",
      "108\n",
      "class 4\n",
      "5\n",
      "class 5\n",
      "19\n",
      "class 6\n",
      "125\n",
      "class 7\n",
      "14\n",
      "class 8\n",
      "109\n",
      "class 9\n",
      "15\n",
      "class 10\n",
      "13\n",
      "class 11\n",
      "7\n",
      "class 12\n",
      "9\n",
      "class 13\n",
      "54\n",
      "class 14\n",
      "21\n",
      "class 15\n",
      "143\n",
      "class 16\n",
      "24\n",
      "class 17\n",
      "7\n",
      "class 18\n",
      "7\n",
      "class 19\n",
      "22\n",
      "class 20\n",
      "6\n",
      "class 21\n",
      "4\n",
      "class 22\n",
      "27\n",
      "class 23\n",
      "12\n",
      "class 24\n",
      "56\n",
      "class 25\n",
      "11\n",
      "class 26\n",
      "14\n",
      "class 27\n",
      "12\n",
      "class 28\n",
      "10\n",
      "class 29\n",
      "4\n",
      "class 30\n",
      "26\n",
      "class 31\n",
      "5\n",
      "class 32\n",
      "4\n",
      "class 33\n",
      "17\n",
      "class 34\n",
      "5\n",
      "class 35\n",
      "21\n",
      "class 36\n",
      "10\n",
      "class 37\n",
      "8\n",
      "class 38\n",
      "46\n",
      "class 39\n",
      "4\n",
      "class 40\n",
      "28\n",
      "class 41\n",
      "4\n",
      "class 42\n",
      "19\n",
      "class 43\n",
      "4\n",
      "class 44\n",
      "8\n",
      "class 45\n",
      "7\n",
      "class 46\n",
      "22\n",
      "class 47\n",
      "5\n",
      "class 48\n",
      "6\n",
      "class 49\n",
      "4\n",
      "class 50\n",
      "10\n",
      "class 51\n",
      "6\n",
      "class 52\n",
      "6\n",
      "class 53\n",
      "5\n",
      "class 54\n",
      "8\n",
      "class 55\n",
      "19\n",
      "class 56\n",
      "9\n",
      "class 57\n",
      "5\n",
      "class 58\n",
      "4\n",
      "class 59\n",
      "4\n",
      "class 60\n",
      "3\n",
      "class 61\n",
      "7\n",
      "class 62\n",
      "3\n",
      "class 63\n",
      "12\n",
      "class 64\n",
      "6\n",
      "class 65\n",
      "5\n",
      "class 66\n",
      "4\n",
      "class 67\n",
      "5\n",
      "class 68\n",
      "7\n",
      "class 69\n",
      "5\n",
      "class 70\n",
      "5\n",
      "class 71\n",
      "5\n",
      "class 72\n",
      "3\n",
      "class 73\n",
      "9\n",
      "class 74\n",
      "4\n",
      "class 75\n",
      "5\n",
      "class 76\n",
      "4\n",
      "class 77\n",
      "10\n",
      "class 78\n",
      "7\n",
      "class 79\n",
      "5\n",
      "class 80\n",
      "5\n",
      "class 81\n",
      "7\n",
      "class 82\n",
      "4\n",
      "class 83\n",
      "5\n",
      "class 84\n",
      "4\n",
      "class 85\n",
      "4\n",
      "class 86\n",
      "4\n",
      "class 87\n",
      "8\n",
      "class 88\n",
      "5\n",
      "class 89\n",
      "5\n",
      "class 90\n",
      "7\n",
      "class 91\n",
      "4\n",
      "class 92\n",
      "4\n",
      "class 93\n",
      "4\n",
      "class 94\n",
      "3\n",
      "class 95\n",
      "4\n",
      "class 96\n",
      "6\n",
      "class 97\n",
      "4\n",
      "class 98\n",
      "6\n",
      "class 99\n",
      "3\n",
      "class 100\n",
      "7\n",
      "class 101\n",
      "3\n",
      "class 102\n",
      "4\n",
      "class 103\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# クラスとそのクラス内のベクトル数\n",
    "\n",
    "n_class = np.max(y_dbscan) +1\n",
    "\n",
    "for n in range(n_class):\n",
    "    print(\"class\", n)\n",
    "    class_n =  len(np.where(y_dbscan == n)[0])\n",
    "    print(class_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n = 1\n",
    "mean_vec_list = [] # 関係ベクトルの配列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0\n",
      "class 1\n",
      "class 2\n",
      "class 3\n",
      "class 4\n",
      "class 5\n",
      "class 6\n",
      "class 7\n",
      "class 8\n",
      "class 9\n",
      "class 10\n",
      "class 11\n",
      "class 12\n",
      "class 13\n",
      "class 14\n",
      "class 15\n",
      "class 16\n",
      "class 17\n",
      "class 18\n",
      "class 19\n",
      "class 20\n",
      "class 21\n",
      "class 22\n",
      "class 23\n",
      "class 24\n",
      "class 25\n",
      "class 26\n",
      "class 27\n",
      "class 28\n",
      "class 29\n",
      "class 30\n",
      "class 31\n",
      "class 32\n",
      "class 33\n",
      "class 34\n",
      "class 35\n",
      "class 36\n",
      "class 37\n",
      "class 38\n",
      "class 39\n",
      "class 40\n",
      "class 41\n",
      "class 42\n",
      "class 43\n",
      "class 44\n",
      "class 45\n",
      "class 46\n",
      "class 47\n",
      "class 48\n",
      "class 49\n",
      "class 50\n",
      "class 51\n",
      "class 52\n",
      "class 53\n",
      "class 54\n",
      "class 55\n",
      "class 56\n",
      "class 57\n",
      "class 58\n",
      "class 59\n",
      "class 60\n",
      "class 61\n",
      "class 62\n",
      "class 63\n",
      "class 64\n",
      "class 65\n",
      "class 66\n",
      "class 67\n",
      "class 68\n",
      "class 69\n",
      "class 70\n",
      "class 71\n",
      "class 72\n",
      "class 73\n",
      "class 74\n",
      "class 75\n",
      "class 76\n",
      "class 77\n",
      "class 78\n",
      "class 79\n",
      "class 80\n",
      "class 81\n",
      "class 82\n",
      "class 83\n",
      "class 84\n",
      "class 85\n",
      "class 86\n",
      "class 87\n",
      "class 88\n",
      "class 89\n",
      "class 90\n",
      "class 91\n",
      "class 92\n",
      "class 93\n",
      "class 94\n",
      "class 95\n",
      "class 96\n",
      "class 97\n",
      "class 98\n",
      "class 99\n",
      "class 100\n",
      "class 101\n",
      "class 102\n",
      "class 103\n"
     ]
    }
   ],
   "source": [
    "for n in range(n_class):\n",
    "    print(\"class\", n)\n",
    "    class_number =  np.where(y_dbscan == n)[0]\n",
    "    # クラスタに含まれる点の数\n",
    "    #print(\"クラスタ\" + str(n) +  \"に含まれる点の数\", len(np.where(data == n)[0]))\n",
    "            \n",
    "    index = list(np.where(y_dbscan == n))\n",
    "    index =list(index[0])\n",
    "    #print(index)\n",
    "            \n",
    "    d = np.array([sample_vec_list[i] for i in index])\n",
    "        \n",
    "    #クラスタの重心\n",
    "    mean = np.mean(d, axis=0)\n",
    "    mean_vec_list.append(mean)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_number =  np.where(y_dbscan == -1)[0]\n",
    "index = list(np.where(y_dbscan == -1))\n",
    "index =list(index[0])\n",
    "d = np.array([sample_vec_list[i] for i in index])\n",
    "\n",
    "for v in d:\n",
    "    mean_vec_list.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35629"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 関係ベクトルを算出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関係ベクトル出力\n",
    "\n",
    "relation_vec_list = []\n",
    "\n",
    "for start in range(len(mean_vec_list)):\n",
    "    f_name = \"../relation_vec_fold/\" + str(start) + \".binaryfile\"\n",
    "    \n",
    "    for i in range(start+1, len(mean_vec_list)):\n",
    "            relarion_vec = mean_vec_list[start] - mean_vec_list[i] \n",
    "            relation_vec_list.append(relarion_vec) \n",
    "            \n",
    "f = open(f_name,'wb')\n",
    "pickle.dump(relation_vec_list,f)\n",
    "f.close\n",
    "relation_vec_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 密なクラスタを算出\n",
    "\n",
    "\n",
    "def generate_mean(i):\n",
    "    # 全体の固有名詞の内、半分をランダムに取得\n",
    "\n",
    "    sample_list = random.sample(mean_vec_list, int(len(mean_vec_list)/10))\n",
    "\n",
    "    eps_minPts = {}\n",
    "    minPts_data = {}\n",
    "\n",
    "    print(\"noun_vec_list数 : \", len(sample_list))\n",
    "\n",
    "    for eps in range(1,10,1):\n",
    "        eps = eps/10\n",
    "    \n",
    "        for minPts in range(2,12, 2):\n",
    "            dbscan = DBSCAN(eps=eps,min_samples=minPts).fit(sample_list)\n",
    "        \n",
    "            y_dbscan = dbscan.labels_\n",
    "        \n",
    "            print(\"y_dbscan\", y_dbscan)\n",
    "        \n",
    "            print(\"eps:\",eps,\",minPts:\", minPts)\n",
    "        \n",
    "            # outlier数\n",
    "            print(\"outlier数\", len(np.where(y_dbscan ==-1)[0]))\n",
    "        \n",
    "            # クラスタ数\n",
    "            print(\"クラスタ数\", np.max(y_dbscan) +1)\n",
    "        \n",
    "            print(\"                            \")\n",
    "        \n",
    "            minPts_data[minPts] = y_dbscan\n",
    "            eps_minPts[eps] = minPts_data\n",
    "        \n",
    "        # DBSCANの結果を保存\n",
    "        f_name = str(i)_str(eps) + \"_\" + str(minPts) + \"_dic.binaryfile\"\n",
    "        save_at = \"../0_1_dbscan_sample_mean_fold/\" + f_name\n",
    "        print(save_at)\n",
    "        f = open(save_at,'wb')\n",
    "        pickle.dump(eps_minPts,f)\n",
    "        f.close\n",
    "    \n",
    "        eps_minPts = {}\n",
    "        minPts_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50): #50*N(パラメータの生成クラス数)クラスできる\n",
    "    generate_mean(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib \n",
    "from scipy import optimize\n",
    "from scipy import stats\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "#plt.rcParams['font.family'] = 'IPAexGothic'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # warningが出ないように設定\n",
    "pd.set_option(\"display.max_rows\", None) # pandasの表示上限をなくす\n",
    "pd.set_option(\"display.max_columns\", None) # pandasの表示上限をなくす\n",
    "import pickle\n",
    "import gspread\n",
    "import json\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import collections\n",
    "import gensim\n",
    "import random\n",
    "\n",
    "model = gensim.models.Word2Vec.load(\"../latest-ja-word2vec-gensim-model/word2vec.gensim.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3696"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"../fact_relation_vec_list.binaryfile\",'rb')\n",
    "#f = open(\"../kansei_relation_vec_list.binaryfile\",'rb')\n",
    "mean_vec_list = pickle.load(f)\n",
    "\n",
    "mean_vec_list = random.sample(mean_vec_list, int(len(mean_vec_list)/20))\n",
    "len(mean_vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Google Spread Sheetsにアクセス\n",
    "def connect_gspread(jsonf,key):\n",
    "    scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_name(jsonf, scope)\n",
    "    gc = gspread.authorize(credentials)\n",
    "    SPREADSHEET_KEY = key\n",
    "    worksheet = gc.open_by_key(SPREADSHEET_KEY).sheet1\n",
    "    return worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_vec_list_generator(imput_word_list):\n",
    "    result_vec_list  = []\n",
    "\n",
    "    for w in imput_word_list:\n",
    "\n",
    "        try:\n",
    "            w_to_v = model.wv[w]\n",
    "\n",
    "            for mean_vec in mean_vec_list:\n",
    "                result_vec_plus = w_to_v - mean_vec \n",
    "                result_vec_minus =   w_to_v + mean_vec \n",
    "    \n",
    "                result_vec_list.append(result_vec_plus)\n",
    "                result_vec_list.append(result_vec_minus)\n",
    "        except:\n",
    "            print(\"Error\", w)\n",
    "\n",
    "    return result_vec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関係ベクトルと類似度が高い単語をn個上位表示\n",
    "def output_word_list_generator(result_vec_list):\n",
    "    output_word_list = []\n",
    "    max_n = 2\n",
    "\n",
    "    for vec in result_vec_list:\n",
    "        most_similar = np.array(list(model.wv.most_similar([vec], [], max_n)))\n",
    "        #output_word_list.extend(most_similar[:,0].tolist())\n",
    "        \n",
    "        a = most_similar[:,1]\n",
    "        for cos in a:\n",
    "            if float(cos) >= 0.85: #コサイン類似度が0.8以下を除去\n",
    "                output_word_list.extend(most_similar[:,0].tolist())\n",
    "                \n",
    "    return output_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ggg(list_taple):\n",
    "    l = []\n",
    "    for taple in list_taple:\n",
    "        a = taple[0]\n",
    "        l.append(a)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここでjsonfile名と2-2で用意したkeyを入力\n",
    "jsonf = \"quickstart-1595337771922-22c2ceb47d3c.json\"\n",
    "spread_sheet_key = \"1WKpQ4sxL_IP9Fm6551xDRfhxhDLzmgGAG3FCzDFmamI\"\n",
    "worksheet = connect_gspread(jsonf,spread_sheet_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# スプレッドシートのデータを取得するコード\n",
    "# {\"answer\":[imput_word_list], ...}\n",
    "\n",
    "data_dic = {}\n",
    "\n",
    "for i in range(2, 33): #すプレッソシートの行数\n",
    "    answers_list = worksheet.row_values(i)\n",
    "    imput_word_list = answers_list[2:]\n",
    "    answer_word = answers_list[1]\n",
    "    \n",
    "    data_dic[answer_word] = imput_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIXIL\n",
      "['トステム', 'INAX', '新日軽', 'サンウエーブ工業', '東洋エクステリア', 'YKK', '大建工業']\n",
      "Error サンウエーブ工業\n",
      "Error 東洋エクステリア\n",
      "Error 大建工業\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-e06d3a6992cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresult_vec_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_vec_list_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimput_word_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutput_word_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_word_list_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_vec_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimput_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimput_word_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-1047e4062c82>\u001b[0m in \u001b[0;36moutput_word_list_generator\u001b[0;34m(result_vec_list)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_vec_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmost_similar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#output_word_list.extend(most_similar[:,0].tolist())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mlimited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_norm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrestrict_vocab\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimited\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for answer_word, imput_word_list in data_dic.items():\n",
    "    print(answer_word)\n",
    "    print(imput_word_list)\n",
    "    \n",
    "    result_vec_list = result_vec_list_generator(imput_word_list)\n",
    "    output_word_list = output_word_list_generator(result_vec_list)\n",
    "    \n",
    "    for imput_word in imput_word_list:\n",
    "        output_word_list = [output_word for output_word in output_word_list if output_word != imput_word]\n",
    "    \n",
    "    c = collections.Counter(output_word_list)\n",
    "    dic = dict(c)\n",
    "    dic2 = sorted(dic.items(), key=lambda x:x[1], reverse=True)\n",
    "    l = ggg(dic2[:30])\n",
    "    print(l)\n",
    "    \n",
    "    if answer_word in l: \n",
    "        print(\"成功**************************\")\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    print(\"　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\")\n",
    "    \n",
    "print(\"正答率\", count/len(data_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range(2, 33): #すプレッソシートの行数\n",
    "    answers_list = worksheet.row_values(i)\n",
    "    imput_word_list = answers_list[2:]\n",
    "    answer_word = answers_list[1]\n",
    "    print(\"answer\", answer_word)\n",
    "    print(\"imput\", imput_word_list)\n",
    "    \n",
    "    result_vec_list = result_vec_list_generator(imput_word_list)\n",
    "    output_word_list = output_word_list_generator(result_vec_list)\n",
    "    \n",
    "    for imput_word in imput_word_list:\n",
    "        output_word_list = [output_word for output_word in output_word_list if output_word != imput_word]\n",
    "    \n",
    "    c = collections.Counter(output_word_list)\n",
    "    dic = dict(c)\n",
    "    dic2 = sorted(dic.items(), key=lambda x:x[1], reverse=True)\n",
    "    l = ggg(dic2[:30])\n",
    "    print(l)\n",
    "    \n",
    "    if answer_word in l: \n",
    "        print(\"成功**************************\")\n",
    "    \n",
    "    print(\"　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複数の単語で類似度の高いものを上から１０個表示する\n",
    "most_similar = np.array(list(model.wv.most_similar(imput_word_list, [], 10)))[:,0]\n",
    "most_similar.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
